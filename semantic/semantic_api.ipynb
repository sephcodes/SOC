{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install typing-extensions==4.8.0\n",
    "# !pip install fastapi\n",
    "# !pip install uvicorn\n",
    "# !pip install pydantic\n",
    "# !pip install requests\n",
    "# !pip install pypi-json\n",
    "# !pip install pyngrok\n",
    "# !pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: evaluate in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (3.9.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.13.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Collecting protobuf<=3.20.2 (from transformers[sentencepiece])\n",
      "  Using cached protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: six in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2022.7)\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-macos 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.2\n",
      "Requirement already satisfied: transformers in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (4.29.2)\n",
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/20/0a/739426a81f7635b422fbe6cb8d1d99d1235579a6ac8024c13d743efa6847/transformers-4.36.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.19.3 from https://files.pythonhosted.org/packages/05/09/1945ca6ba3ad8ad6e2872ba682ce8d68c5e63c8e55458ed8ab4885709f1d/huggingface_hub-0.19.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/c5/0e/8961075de3aca5435fa6371088d44594cdc0e59b5b935afdaf1af028cf36/tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/0c/84/1e59b0594ca421ff308169b0802d72adcce359619925141b69d2ebc89269/safetensors-0.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/70/25/fab23259a52ece5670dcb8452e1af34b89e6135ecc17cd4b54b4b479eac6/fsspec-2023.12.2-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.1-cp311-cp311-macosx_11_0_arm64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.3/426.3 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2023.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2023.12.2 huggingface-hub-0.19.4 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.2\n",
      "Requirement already satisfied: faiss-cpu in /Users/youssefawad/anaconda3/lib/python3.11/site-packages (1.7.4)\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets evaluate 'transformers[sentencepiece]'\n",
    "# # !pip install protobuf==3.20.3\n",
    "# ## !pip install --upgrade protobuf\n",
    "# # !pip install keras==2.15.0\n",
    "# ## !pip install --upgrade keras\n",
    "# # !pip install --upgrade tensorflow\n",
    "# !pip install --upgrade transformers\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_input(BaseModel):\n",
    "    \n",
    "    text : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import transformers\n",
    "# transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFMPNetModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFMPNetModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFMPNetModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFMPNetModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMPNetModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "loaded_dataset = joblib.load(\"embeddings_dataset.joblib\")\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"tf\"\n",
    "    )\n",
    "    encoded_input = {k: v for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post('/soc_prediction')\n",
    "def soc_pred(input_parameters: model_input):\n",
    "    \n",
    "    input_data = input_parameters.json()\n",
    "    input_dictionary = json.loads(input_data)\n",
    "    \n",
    "    text = input_dictionary['text']\n",
    "\n",
    "    #Embed data\n",
    "    text_embedding = get_embeddings([text]).numpy()\n",
    "\n",
    "    scores, samples = loaded_dataset.get_nearest_examples(\n",
    "        \"embeddings\", text_embedding, k=5\n",
    "    )\n",
    "\n",
    "    samples_df = pd.DataFrame.from_dict(samples)\n",
    "    samples_df[\"score\"] = scores\n",
    "    samples_df.sort_values(\"score\", ascending=False, inplace=True)\n",
    "\n",
    "    return [{'label': row.label, 'score': row.score, 'text': row.text} for _, row in samples_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"DUTIES include: apply caulk, sealants, or other agents to installed surfaces; apply grout between joints of bricks or tiles, using grouting trowels; arrange or store materials, machines, tools, or equipment; clean installation surfaces, equipment, tools, work sites, or storage areas, using water, chemical solutions, oxygen lances, or polishing machines; correct surface imperfections or fill chipped, cracked, or broken bricks or tiles, using fillers, adhesives, or grouting materials; cut materials to specified sizes for installation, using power saws or tile cutters; erect scaffolding or other installation structures; locate and supply materials to masons for installation; mix mortar, plaster, and grout, manually or using machines, according to standard formulas; modify material moving, mixing, grouting, grinding, polishing, or cleaning procedures, according to installation or material requirements; move or position materials such as marble slabs, assisting team members using cranes, hoists, or dollies; provide assistance in the preparation, installation, repair, or rebuilding of tile, brick, or stone surfaces; remove damaged tile, brick, or mortar, and clean or prepare surfaces, using pliers, hammers, chisels, drills, wire brushes, or metal wire anchors; remove excess grout or residue from tile or brick joints, using sponges or trowels; transport materials, tools, or machines to installation sites, manually or using conveyance equipment.\"\n",
    "# question_embedding = get_embeddings([question]).numpy()\n",
    "# question_embedding.shape\n",
    "\n",
    "# scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "#     \"embeddings\", question_embedding, k=5\n",
    "# )\n",
    "\n",
    "# samples_df = pd.DataFrame.from_dict(samples)\n",
    "# samples_df[\"scores\"] = scores\n",
    "# samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _, row in samples_df.iterrows():\n",
    "#     print(f\"SOC: {row.label}\")\n",
    "#     print(f\"SCORE: {row.scores}\")\n",
    "#     print(f\"TEXT: {row.text}\")\n",
    "#     print(\"=\" * 50)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2023-12-20T15:26:48-0500 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session obj=csess id=96b12cd6c9dd err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
      "\n",
      "ERROR:  authentication failed: Usage of ngrok requires a verified account and authtoken.\n",
      "ERROR:  \n",
      "ERROR:  Sign up for an account: https://dashboard.ngrok.com/signup\n",
      "ERROR:  Install your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\n",
      "ERROR:  \n",
      "ERROR:  ERR_NGROK_4018\n",
      "ERROR:  \n"
     ]
    },
    {
     "ename": "PyngrokNgrokError",
     "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/youssefawad/Projects/SOC/semantic_api.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/youssefawad/Projects/SOC/semantic_api.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ngrok_tunnel \u001b[39m=\u001b[39m ngrok\u001b[39m.\u001b[39mconnect(\u001b[39m8000\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/youssefawad/Projects/SOC/semantic_api.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPublic URL:\u001b[39m\u001b[39m'\u001b[39m, ngrok_tunnel\u001b[39m.\u001b[39mpublic_url)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/youssefawad/Projects/SOC/semantic_api.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nest_asyncio\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyngrok/ngrok.py:309\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m             options[\u001b[39m\"\u001b[39m\u001b[39mbasic_auth\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [auth]\n\u001b[1;32m    307\u001b[0m         options\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mauth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 309\u001b[0m api_url \u001b[39m=\u001b[39m get_ngrok_process(pyngrok_config)\u001b[39m.\u001b[39mapi_url\n\u001b[1;32m    311\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating tunnel with options: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(options))\n\u001b[1;32m    313\u001b[0m tunnel \u001b[39m=\u001b[39m NgrokTunnel(api_request(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/api/tunnels\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(api_url), method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m, data\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    314\u001b[0m                                  timeout\u001b[39m=\u001b[39mpyngrok_config\u001b[39m.\u001b[39mrequest_timeout),\n\u001b[1;32m    315\u001b[0m                      pyngrok_config, api_url)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyngrok/ngrok.py:153\u001b[0m, in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    149\u001b[0m     pyngrok_config \u001b[39m=\u001b[39m conf\u001b[39m.\u001b[39mget_default()\n\u001b[1;32m    151\u001b[0m install_ngrok(pyngrok_config)\n\u001b[0;32m--> 153\u001b[0m \u001b[39mreturn\u001b[39;00m process\u001b[39m.\u001b[39mget_process(pyngrok_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyngrok/process.py:234\u001b[0m, in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mif\u001b[39;00m is_process_running(pyngrok_config\u001b[39m.\u001b[39mngrok_path):\n\u001b[1;32m    232\u001b[0m     \u001b[39mreturn\u001b[39;00m _current_processes[pyngrok_config\u001b[39m.\u001b[39mngrok_path]\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m _start_process(pyngrok_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyngrok/process.py:395\u001b[0m, in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    392\u001b[0m kill_process(pyngrok_config\u001b[39m.\u001b[39mngrok_path)\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m ngrok_process\u001b[39m.\u001b[39mstartup_error \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mraise\u001b[39;00m PyngrokNgrokError(\u001b[39m\"\u001b[39m\u001b[39mThe ngrok process errored on start: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ngrok_process\u001b[39m.\u001b[39mstartup_error),\n\u001b[1;32m    396\u001b[0m                             ngrok_process\u001b[39m.\u001b[39mlogs,\n\u001b[1;32m    397\u001b[0m                             ngrok_process\u001b[39m.\u001b[39mstartup_error)\n\u001b[1;32m    398\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m     \u001b[39mraise\u001b[39;00m PyngrokNgrokError(\u001b[39m\"\u001b[39m\u001b[39mThe ngrok process was unable to start.\u001b[39m\u001b[39m\"\u001b[39m, ngrok_process\u001b[39m.\u001b[39mlogs)\n",
      "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
     ]
    }
   ],
   "source": [
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
